# Time Series Foundation Models Research at Auton Lab
Time Series Foundation Models are extremely recent. They have shown promising performance across tasks and domains. At the Auton Lab, we are working on building next generation Time Series Foundation Models, and bringing them closer to practice.

<div align="center">
<img width="60%" alt="Time Series Foundation Models are extremely recent" src="https://github.com/user-attachments/assets/fd30b335-11db-44ff-a254-4e86f95bb664">

  <img width="60%" alt="Bringing MOMENT closer to practice" src="https://github.com/user-attachments/assets/5b08b1c8-6fec-4f31-bd0b-8552fbba24bb">
</div>

### About the Auton Lab
The Auton Lab, part of Carnegie Mellon University‚Äôs School of Computer Science, develops Artificial Intelligence for practical solutions to real world problems.

### Open Source Time Series Datasets & Models
1. HuggingFace: https://huggingface.co/AutonLab

### üìñ Recent Papers
1. Potosnak, Willa, Cristian Challu, Mononito Goswami, Michal Wilinski, Nina Zukowska, and Artur Dubrawski. ‚ÄúImplicit Reasoning in Deep Time Series Forecasting.‚Äù In NeurIPS 2024 Workshop on System 2 Reasoning At Scale and NeurIPS 2024 Workshop on Time Series in the Age of Large Models. [[PDF]](https://arxiv.org/pdf/2409.10840) 
2. Michal Wilinski, Mononito Goswami, Nina Zukowska, Willa Potosnak, and Artur Dubrawski. ‚ÄúExploring Representations and Interventions in Time Series Foundation Models.‚Äù In NeurIPS 2024 Workshop on Fine-Tuning in Modern Machine Learning: Principles and Scalability and NeurIPS 2024 Workshop on Time Series in the Age of Large Models. [[PDF]](https://arxiv.org/pdf/2409.12915)
3. Zukowska, Nina, Mononito Goswami, Michal Wilinski, Willa Potosnak, and Artur Dubrawski. ‚ÄúTowards Long-Context Time Series Foundation Models.‚Äù In NeurIPS 2024 Workshop on Fine-Tuning in Modern Machine Learning: Principles and Scalability and NeurIPS 2024 Workshop on Time Series in the Age of Large Models. [[PDF]](https://arxiv.org/pdf/2409.13530?)
4. Cai, Yifu, Arjun Choudhry‚àó, Mononito Goswami‚àó, and Artur Dubrawski. ‚ÄúTimeSeriesExam: A Time Series Understanding Exam‚Äù. In NeurIPS 2024 Workshop on Time Series in the Age of Large Models **(Spotlight)** and ICAIF 2024 Foundation Models for Time Series: Exploring New Frontiers Workshop **(Oral)** [[PDF]](https://arxiv.org/pdf/2410.14752)
5. Choudhry, Arjun, Konrad Szafer, Mononito Goswami, Yifu Cai, and Artur Dubrawski. ‚ÄúDatasets for Time Series Foundation Models‚Äù. ICML 2024 Workshop on Data-Centric Machine Learning Research (DMLR 2024).
6. Cai, Yifu, Arvind Srinivasan, Mononito Goswami, Arjun Choudhry, and Artur Dubrawski. ‚ÄúJoLT: Jointly Learned Representations of Language and Time-Series for Clinical Time-series Interpretation‚Äù Proceedings of the AAAI Conference on Artificial Intelligence (Student Abstract). 2024. **Best student abstract presentation award winner** [[PDF]](https://ojs.aaai.org/index.php/AAAI/article/view/30423)
7. Cai, Yifu, Mononito Goswami, Arjun Choudhry, Arvind Srinivasan and Artur Dubrawski. ‚ÄúJoLT: Jointly Learned Representations of Language and Time-Series.‚Äù Neural Information Processing Systems Workshop on Deep Generative Models for Health (DGM4H NeurIPS) (2023) (Poster) [[PDF]](https://openreview.net/pdf?id=UVF1AMBj9u)
8. Goswami, Mononito, Konrad Szafer, Arjun Choudhry, Yifu Cai, Shuo Li, and Artur Dubrawski. "MOMENT: A Family of Open Time-series Foundation Models." In Forty-first International Conference on Machine Learning. 2024 [[PDF]](https://arxiv.org/pdf/2402.03885)

<div align="center">
<img height ="120px" src="../cmu_logo.png">
<img height ="110px" src="../autonlab_logo.png">
<img height ="110px" src="../MOMENT Logo.png">
</div>
